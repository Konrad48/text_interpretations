{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikacja tekstu przy pomocy metod uczenia maszynowego, na przykładzie ocen produktów spożywczych.\n",
    "\n",
    "Źródło danych https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ładujemy dane do dataframe, ograniczamy się do pierwszych 100 000\n",
    "data = pd.read_csv(filepath_or_buffer='amazon_food_reviews.csv', sep=',', nrows=200000)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czyszczenie danych usuwam część kolumn,\n",
    "df.drop(columns=[\"Id\",\"ProductId\", \"UserId\", \"ProfileName\", \"HelpfulnessNumerator\", \"HelpfulnessDenominator\", \"Time\", \"Summary\"], inplace=True)\n",
    "\n",
    "# Usuwam wiersze z brakującymi danymi\n",
    "df.replace(\"unknown\", np.NAN, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiana recenzji na wektory TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['Text'].iloc[:10]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vocabulary = ['product', 'good', 'has', 'food', 'have', 'of', 'bought']\n",
    "\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),('tfid', TfidfTransformer())]).fit(corpus)\n",
    "\n",
    "# Przykładowa mała macierz częstości słów\n",
    "word_freq_matrix = pipe['count'].transform(corpus).toarray()\n",
    "\n",
    "# Używamy heatmapy z biblioteki seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(word_freq_matrix, annot=True, cmap='coolwarm', xticklabels=vocabulary, yticklabels=list(range(1, len(corpus) + 1)))\n",
    "plt.xlabel('Słowa')\n",
    "plt.ylabel('Dokoument')\n",
    "plt.title('Wystąpienia słów')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "TF(t, d) = \\frac{\\text{Liczba wystąpień słowa } t \\text{ w dokumencie } d}{\\text{Liczba wszystkich słów w dokumencie } d}\n",
    "$$\n",
    "\n",
    "\n",
    "Uwaga, w tym wypadku jako 'wszystkie słowa' rozumiemy które występują w słowniku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_doc = word_freq_matrix.sum(axis=1)\n",
    "\n",
    "# Normalizacja macierzy częstości przez liczbę słów w dokumencie\n",
    "normalized_matrix = word_freq_matrix / word_counts_per_doc[:, None]\n",
    "\n",
    "# Użyjemy seaborn heatmap do wyświetlenia znormalizowanej macierzy\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(normalized_matrix, annot=True, cmap='coolwarm', xticklabels=vocabulary, yticklabels=list(range(1, len(corpus) + 1)))\n",
    "plt.xlabel('Słowa')\n",
    "plt.ylabel('Dokument')\n",
    "plt.title('Wystąpienia słów podzielone przez liczbę słóww dokumencie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "IDF(t, D) = \\ln \\left( \\frac{\\text{Liczba wszystkich dokumentów w zbiorze } D + 1}{\\text{Liczba dokumentów, w których występuje słowo } t + 1} \\right) + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_values = pipe['tfid'].idf_\n",
    "idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Konwertowanie wartości IDF do postaci macierzy (w jednym wierszu)\n",
    "idf_matrix = idf_values.reshape(1, -1)\n",
    "\n",
    "words_indices = vocabulary\n",
    "# Tworzenie wykresu słupkowego dla wartości IDF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(words_indices, idf_values)\n",
    "plt.xlabel('Słowo')\n",
    "plt.ylabel('Wartość IDF')\n",
    "plt.title('Inverted Document Frequency')\n",
    "plt.xticks(words_indices)  # Ustawienie etykiet dla słów\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{TF-IDF}(t,D) =TF(t,d) * IDF(t, D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_matrix = pipe.transform(corpus).toarray()\n",
    "\n",
    "words_indices = vocabulary\n",
    "# Tworzenie wykresu słupkowego dla wartości TF-IDF\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(tfidf_matrix, cmap='viridis', annot=True, fmt='.2f', xticklabels=words_indices)\n",
    "plt.title('Macierz TF-IDF')\n",
    "plt.xlabel('Słowo')\n",
    "plt.ylabel('Dokoument')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Więcej info:  \n",
    "https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a  \n",
    "https://www.youtube.com/watch?v=vZAXpvHhQow&t=281s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wracając no pełnego zbioru danych\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=40000, analyzer='word', lowercase=True)\n",
    "\n",
    "X = tfidf.fit_transform(df['Text'])\n",
    "y = df['Score']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pobieramy nazwy cech z TF-IDF vectorizer\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Tworzymy słownik mapujący nazwy cech do wartości TF-IDF\n",
    "word_scores = dict(zip(feature_names, X[0].toarray()[0]))\n",
    "# Tworzenie chmury słów\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_scores)\n",
    "\n",
    "# Tworzenie wykresu z chmurą słów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Następnie zeestawy dziele na treningowy zbiór i zbiór testowy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifiers  \n",
    "https://www.youtube.com/watch?v=_YPScrckx28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening z LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co to za liczby powyżej?  \n",
    "Precision (Precyzja): Proporcja poprawnie przewidzianych pozytywnych przypadków spośród wszystkich pozytywnych przypadków przewidzianych przez model. \n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "$$\n",
    "\n",
    "Recall (Czułość): Proporcja poprawnie przewidzianych pozytywnych przypadków spośród wszystkich rzeczywiście występujących pozytywnych przypadków w danych.\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "$$\n",
    "\n",
    "F1-Score: To średnia harmoniczna precyzji i czułości. Jest miarą równowagi między precyzją a czułością.\n",
    "$$\n",
    "\\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "Support (Wsparcie): Liczba wystąpień każdej z klas w zbiorze danych testowych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przetestujmy sobie nasz model\n",
    "my_sample_food_review = \"It was ok but woud not buy it again\"\n",
    "predicted_rating = clf.predict(tfidf.transform([my_sample_food_review]))[0]\n",
    "print(\"Predicted rating: \", predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier(random_state=0)\n",
    "clf_dec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_dec.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_neur = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2))\n",
    "clf_neur.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_neur.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a512712789176ca4c435fb38ac45c427fe0ff1bc99ce652e25a1b032cb51e00"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
